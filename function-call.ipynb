{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_openai langchain_community langchain_core -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function call 简介\n",
    "\n",
    "LLM的Function Call（函数调用）是一种功能，允许大型语言模型（如GPT）在生成文本的过程中调用外部函数或服务。通过这种方式，开发者可以定义各种函数，使得LLM能够根据对话的上下文和需求进行调用。这些函数可以用于数据提取、知识检索和API集成等任务，从而增强LLM的能力。\n",
    "具体来说，Function Call的作用包括：\n",
    "\n",
    "- 准确识别用户意图：将用户的语义转化为结构化的指令，从而准确判断需要调用哪个函数及其参数。\n",
    "- 增强对话能力：使得对话代理或聊天机器人能够处理复杂问题，通过调用外部API或知识库提供更相关和有用的响应。\n",
    "- 解决模型的局限性：通过引入工具插件来解决模型在时间处理和专业知识方面的缺陷，如幻觉问题。\n",
    "总结来说：function call能够让你用很少的提示词，让llm输出更加准确，数据结构更加稳定。\n",
    "\n",
    "我们还是用几个场景示例来说明，需要实现的功能如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数学运算示例\n",
    "\n",
    "有一个计算函数，它接受两个整数参数 a 和 b，并返回它们的乘积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试想一下，如果有一段文本`a 为 2 b 是 3`,我们要从一段内容中提取`a` 和 `b`两个参数，并调用`amultiply`，获取结果，需要怎么做。常规步骤如下：\n",
    "1. 写提示词，告诉大模型将内容中的ab提取，并返回json，你可能得给他一些提示词和示例，告诉他必须只输出json的结果，尽管如此，可能还会因为幻觉导致结果不是合法的json。\n",
    "2. 拿到json结果，此时是个json字符串，你需要使用`js`中的`J`SON.parse`转为object或者`python`中的`json.loads(json_string)`转为dict\n",
    "3. 最后把结果传给`amultiply`获取最终结果。\n",
    "\n",
    "\n",
    "```python\n",
    "# 伪代码\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "content = llm.invoke([\n",
    "    SystemMessage(\"从下面内容中提取a、b，并组成json，输出结果只包含json\"),\n",
    "    # fewshot 给出输入输出示例\n",
    "    HumanMessage(\"a 为 2 b 是 3\")\n",
    "])\n",
    "# '{\"a\": 2, \"b\": 3}'\n",
    "\n",
    "# {\"a\": 2, \"b\": 3}\n",
    "jsonData = json.loads(content)\n",
    "\n",
    "# 6\n",
    "amultiply(jsonData)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function_call 示例\n",
    "\n",
    "如果我们使用function_call，这个过程就会变得可控，结果更加准确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from google.colab import userdata\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "@tool\n",
    "def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_BASE\"] = userdata.get('OPENAI_API_BASE')\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(model=\"qwen2.5-72b-instruct\", temperature=0)\n",
    "\n",
    "ll_tool = llm.bind_tools([amultiply])\n",
    "\n",
    "result = ll_tool.invoke('a 为 3 b 是 6')\n",
    "\n",
    "if hasattr(result, 'tool_calls') and result.tool_calls:\n",
    "    print(result.tool_calls[0]['args'])\n",
    "    print(type(result.tool_calls[0]['args']))\n",
    "    \n",
    "    print(amultiply.invoke(result.tool_calls[0]['args']))\n",
    "else:\n",
    "    print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.tools import tool\n",
    "from google.colab import userdata\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_BASE\"] = userdata.get('OPENAI_API_BASE')\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "    \n",
    "idl1 = \"\"\"\n",
    "message ToolRequest {\n",
    "    string tool_id = 1;  // 工具的唯一标识符\n",
    "    int32 version = 2;   // 工具的版本号\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "idl2 = \"\"\"\n",
    "message ToolRequest {\n",
    "    string tool_name = 1;  // 工具的名称\n",
    "    int32 version = 2;     // 工具的版本号\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "idl3 = \"\"\"\n",
    "message ToolRequest {\n",
    "    string tool_category = 1;  // 工具的类别\n",
    "    int32 version = 2;         // 工具的版本号\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "idl4 = \"\"\"\n",
    "message ToolRequest {\n",
    "    string tool_description = 1;  // 工具的描述信息\n",
    "    int32 version = 2;            // 工具的版本号\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "class InterfaceDefinition(TypedDict):\n",
    "    path: str\n",
    "    description: str\n",
    "\n",
    "class PSMDefinition(TypedDict):\n",
    "    name: str\n",
    "    interfaces: List[InterfaceDefinition]\n",
    "    \n",
    "\n",
    "interfaceMap: List[PSMDefinition] = [\n",
    "    {\n",
    "        \"name\": \"anchor.psm1\",\n",
    "        \"interfaces\": [\n",
    "            {\n",
    "                \"path\": \"/ark/anchor1\",\n",
    "                \"idl\": idl1\n",
    "            },\n",
    "            {\n",
    "                \"path\": \"/ark/anchor2\",\n",
    "                \"idl\": idl2\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"webcast.psm2\",\n",
    "        \"interfaces\": [\n",
    "            {\n",
    "                \"path\": \"/webcast/tool1\",\n",
    "                \"idl\": idl3\n",
    "            },\n",
    "            {\n",
    "                \"path\": \"/webcast/tool2\",\n",
    "                \"idl\": idl4\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "def find_idl_by_name_and_path(psm, path):\n",
    "    for psmInfo in interfaceMap:\n",
    "        if psmInfo[\"name\"] == psm:\n",
    "            for interface in psmInfo[\"interfaces\"]:\n",
    "                if interface[\"path\"] == path:\n",
    "                    return interface[\"idl\"]\n",
    "\n",
    "class ConfigDict(BaseModel):\n",
    "    path: str = Field(description=\"包含 path 和 psm 的字典\")\n",
    "    psm: str = Field(description=\"接口对应的psm，示例：aaa.bbb.ccc，字母和.组成\")\n",
    "\n",
    "class ExplainKeyByPathInput(BaseModel):\n",
    "    queryInfo: ConfigDict = Field(description=\"包含 path 和 psm 的字典\")\n",
    "    keyName: str = Field(description=\"字段名称\")\n",
    "\n",
    "@tool(\"explain-key-by-path\", args_schema=ExplainKeyByPathInput)\n",
    "def explain_key_by_path(\n",
    "    queryInfo: ConfigDict,  # 定义一个包含 path 和 psm 的字典\n",
    "    keyName: Annotated[str, \"字段名称\"],\n",
    "):\n",
    "    \"\"\"字段解释工具，通过接口地址和接口对应的psm查找接口定义，并根据字段名来获取字段说明\"\"\"\n",
    "    # 你可以选择不使用 config 参数\n",
    "    print(queryInfo)\n",
    "    idl = find_idl_by_name_and_path(**queryInfo.dict())  # 将 ConfigDict 转换为字典\n",
    "    \n",
    "    return idl\n",
    "\n",
    "print(explain_key_by_path.args_schema.schema())\n",
    "\n",
    "llm2 = ChatOpenAI(model=\"qwen2.5-72b-instruct\", temperature=0)\n",
    "\n",
    "llm_tool = llm2.bind_tools([explain_key_by_path])\n",
    "\n",
    "result = llm_tool.invoke('查询psm:webcast.psm2 接口 /webcast/tool2 中的 tool_name字段')\n",
    "\n",
    "if hasattr(result, 'tool_calls') and result.tool_calls:\n",
    "    print(result.tool_calls[0]['args'])\n",
    "    print(explain_key_by_path.invoke(result.tool_calls[0]['args']))\n",
    "else:\n",
    "    print(result.content)\n",
    "\n",
    "\n",
    "\n",
    "# # 示例使用\n",
    "# name = \"anchor.psm1\"\n",
    "# path = \"/ark/anchor2\"\n",
    "# idl = find_idl_by_name_and_path(name, path)\n",
    "# print(idl)  # 输出: idl1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
